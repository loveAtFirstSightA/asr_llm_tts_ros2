## 1 概述
本文档是讯飞“6+0”麦克风使用注意事项(2019.11.13)
在sdk中sample目录中给出了麦克风的应用demo，帮助对麦克风的功能进行熟悉，分别是基本功能使用案例，离线命令词识别和交互功能案例，在线AIUI交互案例，用户可以参照这几个案例进行其他自定义功能的编写。

## 2.SDK使用
### 2.1 拷贝和解压
拷贝sdk拷贝到系统任一目录中，切换到该目录中.
其中包含了sdk -vvui 以及在ros中使用的功能包vvui_ros-master，本文档仅描述SDK，ros功能包使用说明见功能包中的readme.md.

### 2.2 udev rules检查
若为初次使用，且未配置过本麦克风的udev规则，则执行如下指令进行配置,若已配置过，可忽略该步骤。注：xf_mic.rules位于根目录。
```
$ sudo cp xf_mic.rules /etc/udev/rules.d/
```
然后执行如下指令重启udev服务:
```
$ sudo service udev restart
```
再次插拔麦克风设备即可。
## 3.SDK介绍
其目录结构如下：
├── audio
│   ├── mic_demo_vvui_deno.pcm
│   ├── mic_demo_vvui_ori.pcm
│   └── vvui_deno.pcm
├── bin
│   ├── AIUI
│   ├── call.bnf
│   ├── jetbot_move
│   ├── mic_demo_sample
│   ├── msc
│   └── offline_command_sample
├── include
│   ├── aiui
│   ├── cJSON.h
│   ├── cJSON_Utils.h
│   ├── hidapi.h
│   ├── libusb.h
│   ├── msp_cmn.h
│   ├── msp_errors.h
│   ├── msp_types.h
│   ├── protocol_proc_unit.h
│   ├── qise.h
│   ├── qisr.h
│   ├── qtts.h
│   ├── queue_internal.h
│   └── queue_simple.h
├── lib
│   ├── ARM
│   ├── x64
│   └── x86
├── readme.md
├── sample
│   ├── aiui_sample
│   ├── mic_demo_sample
│   └── offline_command_sample
└── tmp
    ├── all.pcm
    ├── config.txt
    ├── in.pcm
    └── system.tar

其中：
1）audio：用于存放录制的音频文件，音频文件的命名是自定义的，以sample文件夹中给出的mic_demo_sample为例，其程序中定义的降噪后音频文件的命名为mic_demo_vvui_deno.pcm，原始音频文件命名为mic_demo_vvui_ori.pcm。
2）bin：用于存放可执行文件，call.bnf为自定义的离线命令词识别语法，可根据自己实际场景进行更改，更改方法详见4.3.4节。
3）include：包含麦克风阵列启动、给定案例中需要的头文件。
4）lib：包含麦克风阵列启动、给定案例中需要的动态库文件，为了兼容不同的平台，给定了兼容Jetson Nano的ARM版动态库，以及兼容x64系统、x86系统的动态库。
5）sample：包含给出的三个演示案例，分别是：
->mic_demo_sample:麦克风基本功能测试用例，熟悉麦克风开机、录音、设置主麦方向、获取唤醒角度等基础功能演示demo；
->offline_command_sample:离线命令词识别用例，通过离线命令词识别进行控制机器人运动，使用技术为讯飞离线命令词识别功能；
->aiui_sample:在线交互用例，通过在线AIUI进行实时交互，可提供查询、闲聊等能力，该功能基于讯飞AIUI平台。
该三个用例主要用于让用户熟悉麦克风阵列涉及到的API，用户可参照这三个案例进行修改来创建自己期望的实例。
6）tmp：包含文件麦克风阵列板所需的资源文件，常态下可设为隐藏文件，用户可忽略。

## 4.案例使用过程

### 4.1.读取设备
将麦克风阵列通过usb口插到Nano上，然后在NANO上打开终端，运行如下命令，查看是否检测到设备:

```
$ lsusb
```
若检测到VID：PID为10d6：b003的设备，则设备读取成功.
### 4.2 mic_demo_sample-麦克风阵列基础功能测试用例

#### 4.2.1 动态库配置
可选方式有多种，推荐如下两种方式，任意一种均可．

**方式一：**

首先进入IFLYTEK_MIC_SDK3文件中，使用如下命令切换到lib目录下:
```
$ cd ./vvui/lib
```

若主机是ARM64操作系统，则执行如下命令：
```
$ cd arm64 && sudo cp lib* /usr/lib

若主机是ARM32操作系统，则执行如下命令：
```
$ cd arm32 && sudo cp lib* /usr/lib
```
若主机是X64操作系统，则执行如下命令：
```
$ cd x64 && sudo cp lib* /usr/lib
```
**方式二：**

将lib下的动态库路径添加到用户Nano或PC上的/etc/ld.so.conf。

若为arm64平台，则执行如下命令：
```
$ sudo echo "~/vvui/lib/arm64/" >>/etc/ld.so.conf  
```  
注：/*"~/vvui/lib"务必修改为实际使用时的绝对地址*/

若为arm32平台，则执行如下命令：
```
$ sudo echo "~/vvui/lib/arm32/" >>/etc/ld.so.conf  
```  
注：/*"~/vvui/lib"务必修改为实际使用时的绝对地址*/

若为x64位PC，则执行如下命令：
```
$ sudo echo "~/vvui/lib/x64/" >>/etc/ld.so.conf    
```
注：/*"~/vvui/lib"务必修改为实际使用时的绝对地址*/

**执行如下命令，使配置生效：**
```	
$ sudo /sbin/ldconfig
```
#### 4.2.2 生成可执行文件
切换到mic_demo_sample所在的目录：
```
$ cd vvui/sample/mic_demo_sample
```
注：若您刚选择的方式一，则直接运行相对目录即可:$ cd ../../sample/mic_demo_sample

依照自己的运行平台进行编译脚本文件的选择，若运行平台为arm64平台，则运行如下指令可生成可执行文件：
```
$ sh ./armv8_make.sh
```

依照自己的运行平台进行编译脚本文件的选择，若运行平台为arm32平台，则运行如下指令可生成可执行文件：
```
$ sh ./arm32_make.sh
```

若平台为linux64位操作系统，则运行如下指令：
```
$ sh ./64bit_make.sh
```
执行完上述命令后，会在bin目录中看到可执行文件.

#### 4.2.3 切换到bin目录下，可以执行生成的可执行文件。
在刚才的目录下，执行如下命令后，会切换到bin目录下．
```
$ cd ../../bin
```
执行如下命令，即执行生成的可执行文件．
```
$ sudo ./mic_demo_sample
```
注：sudo也可省略。

#### 4.2.4 测试
运行完成后，会提示1-9的命令，其中：
1）1命令是麦克风阵列开机操作，注意，在将麦克风阵列插入到Jetson Nano上时，麦克风阵列并未开机和运行。当系统检测到麦克风阵列新插入到Nano上，会进行诸如资源等一系列开机动作，在终端描述为“系统开机中”。若不出现拔插麦克风操作，仅重新启动这个节点，则不再需要开机动作，在终端描述为“系统开机正常”，终端描述为"系统正在升级"，此时麦克风灯亮，等到灯灭，即为升级完成，此时按下１命令，即为开机操作．
2)2命令是录制麦克风降噪音频的操作，在次之前请务必用唤醒词“小V小V”进行唤醒，否则是无法获取音频的，唤醒成功后，按下2，则开始进行录音，且在audio文件夹中会看到录制的降噪后音频mic_demo_vvui_deno.pcm。
3)3命令是停止录制麦克风降噪音频，按下3，则停止录制降噪后音频。
4)4命令是录制麦克风原始音频的操作，若在此之前麦克风阵列未被唤醒过，仍然需要再唤醒后进行操作，按下4，则开始正常录音，且在audio文件夹中会看到录制的原始音频mic_demo_vvui_ori.pcm。
5)5命令是停止录制麦克风原始音频，按下5即停止。
6)6是设置麦克风的主麦方向，可设置6个麦克风中的任意一个为主麦。
7)7命令, 获取主麦克风id。
8)8命令, 走马灯体验。

### 4.3 offline_command_sample-离线命令词识别用例
本案例（offline_command_sample）为离线命令词识别用例，用户可使用自定义的离线命令词的关键字进行离线下的命令下发。使用过程如下：
#### 4.3.1 动态库配置
(注：此步骤同案例一mic_demo_sample中的配置过程，若在案例一中已配置动态库，可直接忽略此步骤，直接执行2)
可选方式有多种，推荐如下两种方式，任意一种均可：

**方式一：**
首先需进入到IFLYTEK_MIC_SDK3中，使用如下命令切换到lib目录下:
```
$ cd ./vvui/lib
```

若主机是ARM64操作系统，则执行如下命令：
```
$ cd arm64 && sudo cp lib* /usr/lib

若主机是ARM32操作系统，则执行如下命令：
```
$ cd arm32 && sudo cp lib* /usr/lib
```
若主机是X64操作系统，则执行如下命令：
```
$ cd x64 && sudo cp lib* /usr/lib
```
**方式二：**

将lib下的动态库路径添加到用户Nano或PC上的/etc/ld.so.conf。

若为arm64平台，则执行如下命令：
```
$ sudo echo "~/vvui/lib/arm64/" >>/etc/ld.so.conf  
```  
注：/*"~/vvui/lib"务必修改为实际使用时的绝对地址*/

若为arm32平台，则执行如下命令：
```
$ sudo echo "~/vvui/lib/arm32/" >>/etc/ld.so.conf  
```  
注：/*"~/vvui/lib"务必修改为实际使用时的绝对地址*/
                ```
若为x64位PC，则执行如下命令：
```
$ sudo echo "~/vvui/lib/x64/" >>/etc/ld.so.conf    
```
注：/*"~/vvui/lib"务必修改为实际使用时的绝对地址*/
**执行如下命令，使配置生效：**
```
$ sudo /sbin/ldconfig
```

#### 4.3.2 生成可执行文件
切换到offline_command_sample所在的目录：
```
$ cd vvui/sample/offline_command_sample
```
(若您刚选择的为方式一，则直接运行相对目录即可:$ cd ../../sample/offline_command_sample）

依照自己的运行平台进行编译脚本文件的选择，若运行平台为arm64平台，则运行如下指令可生成可执行文件：
```
$ sh ./armv8_make.sh
```

依照自己的运行平台进行编译脚本文件的选择，若运行平台为arm32平台，则运行如下指令可生成可执行文件：
```
$ sh ./arm32_make.sh
```

若平台为linux64位操作系统，则运行如下指令：
```
$ sh ./64bit_make.sh
```
执行完如下命令后，会在bin目录中看到可执行文件.

#### 4.3.3 切换到bin目录下，可以执行生成的可执行文件．
注意：在执行生成的可执行文件之前，需要检查一下离线资源路径是否正确设置以及检查文件是否可读或是否损坏，在offline_command_sample所在的目录下可以看到user_interface.h用户接口文件．语法识别资源路径、语法路径、音频文件保存地址等可设置为绝对路径和相对路径.若选择使用相对路径，则修改第五行为：
```
#define Relative_Path 1
```
注意使用相对路径时，必须在bin目录下.
若选择使用绝对路径，则修改第五行为：
```
#define Relative_Path 0
```
然后将离线语法识别资源路径、构建离线语法识别网络生成数据保存路径、构建离线识别语法网络所用的语法文件路径、录音文件保存的地址、资源文件存储地址改为绝对路径.修改完之后在刚才的目录下，执行如下命令后，会切换到bin目录下:
```
$ cd ../../bin
```
执行如下命令，即执行生成的可执行文件．
```
$ sudo ./offline_command_sample
```
：sudo也可省略。
#### 4.3.4 测试

与mic_demo_sample不同的是，本案例不再是分步操作，而是连续地自动操作，即首先检测麦克风阵列是否开机，若未开机就等待其开机，开机完成后则进入待唤醒状态。此时会提醒用户进行唤醒，若检测到唤醒成功则自动开启录音，此时说出离线命令词即可进行识别。注意：

1）离线命令词为自定义的应用场景所创建的，在本例中是为控制机器人运动，其命令词包含：
【你】【往、向】【前、后、左、右】【走、转】，用户说出这四组关键字中任一组合均可识别，如“往前走”、“向后走”、“向左转”、“左转”等。若要对关键字进行修改，可修改bin目录中的call.bnf文件，其格式如下：
```
﻿﻿#BNF+IAT 1.0 UTF-8;
!grammar call;
!slot <want>;
!slot <direction>;
!slot <do>;
!slot <what>;

!start <callstart>;
<callstart>:[<want>]<dowhat>;
<want>:向|往|你往|你向;
<dowhat>:<direction><do>;
<direction>:左!id(10001)|右!id(10001)|前!id(10001)|后!id(10001);
<do>:走!id(10001)|移动!id(10001)|转!id(10001)|动!id(10001)|动动!id(10001);
```
2）离线命令词识别本例中给出的离线命令词是需要输入录制音频文件后进行识别，即给定4秒中的时间进行录音命令，然后进行命令词识别。用户可参照本例和讯飞开放平台中离线命令词识别SDK进行更改，以实现不保存录音文件，直接对用户语音进行处理，根据VAD来判断语音的开头和结尾。
#### 4.3.5 进阶
用户除了可以根据自己的应用场景修改bnf外，还可以在user_interface.h中修改包括置信度在内的一些参数，以此来增加识别的精度，具体见文档注释。
在offline_command_sample所在的目录下，可以看到user_interface.h用户接口文件．
运行效果调试参数说明如下:
1)confidence为置信度阈值，当置信度大于所设定阈值时，则认为唤醒成功．用户可根据麦克风使用环境设置该值，若当前环境检测容易出错，则适当调大该值，减少出错率.
2)awake_words[30]为使用的唤醒词，可根据需求自己修改．
3)time_per_order为一次命令时长，当说话人说话时长大于该值，则麦克风会自动忽略该时长之后的话，可根据需求自己修改．
4)awake_count为一次唤醒，可允许对话的次数，超过该次数则需要重新唤醒麦克风．
文档中各参数设置如下：
　　　　　　　　```
	int confidence = 40; //置信度阈值，可根据麦克风使用环境进行设置，若容易检测出错，则调大该值。
　　　　　　　　char awake_words[30] = "小Ｖ小Ｖ"; //使用的唤醒词
　　　　　　　　int time_per_order = 3;//一次命令时长
　　　　　　　　int awake_count = 5;//一次唤醒，可允许对话的次数
	```
可根据实际需求自行修改．
### 4.4 aiui_sample-在线人机交互案例
#### 4.4.1切换到aiui_sample所在的目录．
在vvui下的sample中，使用如下命令切换到aiui_sample所在的目录：
```
$ cd aiui_sample
```
#### 4.4.2 修改CMakeLists.txt文件:
该项主要是根据主机系统来修改动态库路径,若x64系统,则修改16-20行内容如下:

```
link_directories(
../../lib
../../lib/x64 
#../../libs/arm64
#../../libs/arm32
)
```
若为ARM64系统,则修改16-20行内容如下:
```
link_directories(
../../lib
#../../lib/x64 
../../lib/arm64
#../../lib/arm32
)
```
若为ARM32系统,则修改16-20行内容如下:
```
link_directories(
../../lib
#../../lib/x64 
#../../lib/arm64
../../lib/arm32
)
```
#### 4.4.3 编译
首先进入build目录:
```
$ cd build
```
注：编译之前要把bulid里面上次编译产生的一系列文件删除，才可以重新编译，可以直接用如下命令:
```
$ sh clean_make.sh
```
运行clean_make.sh文件，若提示需要删除文件是被保护文件，用户输入y即可删除．
删除完之后执行如下命令进行编译：
```
$ cmake ..
$ make
```
#### 4.4.4 运行
执行如下命令即可体验aiui交互:
```
$ sudo ./demo
```
使用唤醒词"小v小v"即可对麦克风板进行唤醒,唤醒后即进入交互状态.
我们提供的交互方式是continues方式，即一次唤醒多次交互的方式，用户在该方式下可以体验到中途打断的功能，在它回答问题中，可以接着说出下一个问题，这时会自动回答下一个问题；还有一种交互方式为oneshot方式，支持一次唤醒一次交互的方式，用户可以在aiui.cfg文件中修改．执行如下命令：
```
$ cd build/AIUI/cfg
```
找到aiui.cfg文件，修改该文件的65行，若交互方式为continues方式，修改如下：
	"interact_mode":"continuous"
若交互方式为oneshot方式，修改如下：
	"interact_mode":"oneshot"
此外我们提供用户在交互时一句话的开始和结束标志，比如问＂明天天气怎么样？＂，不会在该句话没结束之前麦克风就做出回应，可以增加用户的体验感．
服务端保存用户交互历史的时间最长为120s,即如果用户说＂明天天气怎么样？＂，接下来说＂后天呢？＂，会默认回答后天天气状况，多轮对话最长时间为120s.
每次交互过程中产生的音频文件会保存下来，实时播放，为了避免文件过大，我们在每次唤醒时会自动清除上次交互产生的文件．
在正常交互过程中事件的状态会标识为＇tts＇,即文字到语音的转化．当用户使用技能命令词"你去休息吧"，事件的状态标识为＇nlp＇,此时麦克风会进入休眠模式，不会进行交互，若要重新进入交互模式需要再次使用"小v小v"进行唤醒.
注意:若在使用过程中,可能会出现不能交互,且报错代码为11201的情况,原因是本案例绑定的appid是个人的,单日的交互次数受限,用户可以替换为自己的appid,用户可通过修改AIUITester.cpp文件中的AIUITester::createAgent函数里面的字符串appid以及key,分别对应id和密码．然后开通常用的语料和技能进行使用,在后续使用中若再次遇到报错代码为11201的情况，用户可前往控制台检查对应appid次数是否超过限制次数，超过可在官网产品页面领取免费包或者购买套餐包，未超过可提交技术工单．离线服务接口报错其他常见错误可见https://www.xfyun.cn/document/error-code/.

